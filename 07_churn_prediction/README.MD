# Предсказание оттока клиентов в банке

### Задача

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. 

### Данные

Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком: id клиента, кредитный рейтинг, страна проживания, пол, возраст, сколько лет человек является клиентом банка, баланс на счёте, количество продуктов банка, используемых клиентом,  наличие кредитной карты, предполагаемая зарплата, факт ухода клиента (целевой признак).

### Ход работы

1. Знакомство с данными.
2. Подготовка данных:
    1. обработка пропусков,
    2. прямое кодирование категориальных признаков,
    3. разбиение данных на обучающую и тестовую выборки,
    4. масштабирование признаков.
3. Подготовка к исследованию моделей:
    1. исследование баланса классов,
    2. создание вспомогательных функций: для расчета метрик качества, для построения кривой ошибок, для построения графика значимости признаков.
4. Исследование качества моделей, обученных на несбалансированных данных: обучение моделей и анализ метрик качества классификации на валидации.
5. Исследование способов борьбы с дисбалансом:
    1. upsampling,
    2.  уравновешивание классов,
    3. изменение порога классификации,
    4. сравнение способов борьбы с дисбалансом.
6. Тестирование лучшей модели.

### Выводы

Мы попробовали три способа борьбы с дисбалансом: upsampling, уравновешивание классов и изменение порога классификации.

![Таблица с результатами исследования моделей](https://github.com/alexander-saushev/classic_ml_projects/blob/main/07_churn_prediction/results.png)

Лучше всех себя показал upsampling: дерево решений и случайный лес получили с ним максимальные F1-меры, логистическая регрессия — почти максимальную.

Также upsampling дал наиболее сбалансированную пару recall и precision для всех моделей. Модели, обученные на данных с другой обработкой дисбаланса, чаще начинали слишком активно записывать клиентов в отток, повышая recall и жертвуя precision. Особенно это заметно на дереве решений и логистической регрессии.

Еще мы заметили, что наибольший прирост качества от борьбы с дисбалансом получает логистическая регрессия. Скорее всего, это связано с тем, что изначально у нее были самые низкие метрики, сильно отстающие от других моделей. Борьба с дисбалансом сократила это расстояние.

![Таблица с отсортированными по F1-мере результатами исследования моделей](https://github.com/alexander-saushev/classic_ml_projects/blob/main/07_churn_prediction/results_sorted.png)

Однако если мы отсортируем результаты экспериментов по убыванию F1-меры, то увидим, что бОльшую роль все-таки играет архитектура модели, а не исправление дисбаланса.

Так, первые три места занимает случайный лес с разными обработками дисбаланса. Вторая тройка мест — за деревом решений. Логистическая регрессия проигрывает лесу и дереву, даже когда обучалась с учетом дисбаланса классов.

### Используемые инструменты

pandas, numpy, matplotlib, seaborn, sklearn